{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Fashion WGAN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reveondivad/ExData_Plotting1/blob/master/Copy_of_Fashion_WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkVHjjRfJ7Dg"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tqdm\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from glob import glob\r\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzGtbSswKQk2",
        "outputId": "2c1b851d-7367-4d8b-c5f2-e1e5ac774025"
      },
      "source": [
        "IMG_SHAPE = (28, 28, 1)\r\n",
        "BATCH_SIZE = 512\r\n",
        "noise_dim = 128\r\n",
        "\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist\r\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n",
        "print(f\"Number of examples:  {len(train_images)}\")\r\n",
        "print(f\"Shape of the images: {train_images.shape[1:]}\")\r\n",
        "\r\n",
        "train_images = train_images.reshape(train_images.shape[0], *IMG_SHAPE).astype(\"float32\")\r\n",
        "train_images = (train_images - 127.5) / 127.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Number of examples:  60000\n",
            "Shape of the images: (28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrj1y9e-Kc48",
        "outputId": "7482d12d-613f-4de7-b835-920cb2ebdd3d"
      },
      "source": [
        "def conv_l(\r\n",
        "    x,\r\n",
        "    filters,\r\n",
        "    activation,\r\n",
        "    kernel_size=(3,3),\r\n",
        "    strides=(1,1),\r\n",
        "    padding=\"same\",\r\n",
        "    use_bias=True,\r\n",
        "    use_bn=False,\r\n",
        "    use_dropout=False,\r\n",
        "    drop_value=0.5,\r\n",
        "):\r\n",
        "    x = layers.Conv2D(\r\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\r\n",
        "    )(x)\r\n",
        "    if use_bn:\r\n",
        "      x =layers.BatchNormalization()(x)\r\n",
        "    x = activation(x)\r\n",
        "    if use_dropout:\r\n",
        "      x = layers.Dropout(drop_value)(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def get_discriminator_model():\r\n",
        "  img_input = layers.Input(shape=IMG_SHAPE)\r\n",
        "  x = layers.ZeroPadding2D((2, 2))(img_input)\r\n",
        "  x = conv_l(\r\n",
        "      x,\r\n",
        "      64,\r\n",
        "      kernel_size = (5,5),\r\n",
        "      strides=(2,2),\r\n",
        "      use_bn=False,\r\n",
        "      use_bias=True,\r\n",
        "      activation=layers.LeakyReLU(0.2),\r\n",
        "      use_dropout=False,\r\n",
        "      drop_value=0.3,\r\n",
        "  )\r\n",
        "  x = conv_l(\r\n",
        "      x,\r\n",
        "      128,\r\n",
        "      kernel_size = (5,5),\r\n",
        "      strides=(2,2),\r\n",
        "      use_bn=False,\r\n",
        "      activation=layers.LeakyReLU(0.2),\r\n",
        "      use_bias=True,\r\n",
        "      use_dropout=True,\r\n",
        "      drop_value=0.3,\r\n",
        "  )\r\n",
        "  x = conv_l(\r\n",
        "      x,\r\n",
        "      256,\r\n",
        "      kernel_size = (5,5),\r\n",
        "      strides=(2,2),\r\n",
        "      use_bn=False,\r\n",
        "      activation=layers.LeakyReLU(0.2),\r\n",
        "      use_bias=True,\r\n",
        "      use_dropout=True,\r\n",
        "      drop_value=0.3,\r\n",
        "  )\r\n",
        "  x = conv_l(\r\n",
        "      x,\r\n",
        "      512,\r\n",
        "      kernel_size = (5,5),\r\n",
        "      strides=(2,2),\r\n",
        "      use_bn=False,\r\n",
        "      activation=layers.LeakyReLU(0.2),\r\n",
        "      use_bias=True,\r\n",
        "      use_dropout=False,\r\n",
        "      drop_value=0.3,\r\n",
        "  )\r\n",
        "    \r\n",
        "  x = layers.Flatten()(x)\r\n",
        "  x = layers.Dropout(0.2)(x)\r\n",
        "  x = layers.Dense(1)(x)\r\n",
        "\r\n",
        "  d_model = keras.models.Model(img_input, x, name=\"discriminator\")\r\n",
        "  return d_model\r\n",
        "\r\n",
        "d_model = get_discriminator_model()\r\n",
        "d_model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 16, 16, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 4,305,409\n",
            "Trainable params: 4,305,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHCcGUkiWKWj",
        "outputId": "c7d16f84-89be-471c-9909-d14d7d70d76b"
      },
      "source": [
        "def upsample_block(\r\n",
        "    x,\r\n",
        "    filters,\r\n",
        "    activation,\r\n",
        "    kernel_size=(3,3),\r\n",
        "    strides=(1,1),\r\n",
        "    up_size=(2,2),\r\n",
        "    padding=\"same\",\r\n",
        "    use_bn=False,\r\n",
        "    use_bias=True,\r\n",
        "    use_dropout=False,\r\n",
        "    drop_value=0.3,\r\n",
        "):\r\n",
        "    x = layers.UpSampling2D(up_size)(x)\r\n",
        "    x = layers.Conv2D(\r\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\r\n",
        "    )(x)\r\n",
        "\r\n",
        "    if use_bn:\r\n",
        "      x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    if activation:\r\n",
        "      x = activation(x)\r\n",
        "    if use_dropout:\r\n",
        "      x = layers.Dropout(drop_value)(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "def get_generator_model():\r\n",
        "  noise = layers.Input(shape=(noise_dim,))\r\n",
        "  x = layers.Dense(4 * 4 * 256, use_bias=False)(noise)\r\n",
        "  x = layers.BatchNormalization()(x)\r\n",
        "  x = layers.LeakyReLU(0.2)(x)\r\n",
        "\r\n",
        "  x = layers.Reshape((4, 4, 256))(x)\r\n",
        "  x = upsample_block(\r\n",
        "      x,\r\n",
        "      128,\r\n",
        "      layers.LeakyReLU(0.2),\r\n",
        "      strides=(1, 1),\r\n",
        "      use_bias = False,\r\n",
        "      use_bn=True,\r\n",
        "      padding=\"same\",\r\n",
        "      use_dropout=False,\r\n",
        "  )\r\n",
        "  x = upsample_block(\r\n",
        "      x,\r\n",
        "      64,\r\n",
        "      layers.LeakyReLU(0.2),\r\n",
        "      strides=(1,1),\r\n",
        "      use_bias=False,\r\n",
        "      use_bn=True,\r\n",
        "      padding=\"same\",\r\n",
        "      use_dropout=False,\r\n",
        "  )\r\n",
        "\r\n",
        "  x = upsample_block(\r\n",
        "      x, 1, layers.Activation(\"tanh\"), strides=(1,1), use_bias=False, use_bn=True\r\n",
        "  )\r\n",
        "  x=layers.Cropping2D((2,2))(x)\r\n",
        "\r\n",
        "  g_model = keras.models.Model(noise, x, name=\"generator\")\r\n",
        "  return g_model\r\n",
        "\r\n",
        "g_model = get_generator_model()\r\n",
        "g_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              524288    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        73728     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 1)         576       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 1)         4         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "cropping2d (Cropping2D)      (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 910,660\n",
            "Trainable params: 902,082\n",
            "Non-trainable params: 8,578\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEA27GcsdA-f"
      },
      "source": [
        "class WGAN(keras.Model):\r\n",
        "  def __init__(\r\n",
        "      self,\r\n",
        "      discriminator,\r\n",
        "      generator,\r\n",
        "      latent_dim,\r\n",
        "      discriminator_extra_steps=3,\r\n",
        "      gp_weight=10.0,\r\n",
        "\r\n",
        "  ):\r\n",
        "      super(WGAN, self).__init__()\r\n",
        "      self.discriminator = discriminator\r\n",
        "      self.generator = generator\r\n",
        "      self.latent_dim = latent_dim\r\n",
        "      self.d_steps = discriminator_extra_steps\r\n",
        "      self.gp_weight = gp_weight\r\n",
        "    \r\n",
        "  def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\r\n",
        "    super(WGAN, self).compile()\r\n",
        "    self.d_optimizer = d_optimizer\r\n",
        "    self.g_optimizer = g_optimizer\r\n",
        "    self.d_loss_fn = d_loss_fn\r\n",
        "    self.g_loss_fn = g_loss_fn\r\n",
        "\r\n",
        "\r\n",
        "  def gradient_penalty(self, batch_size, real_images, fake_images):\r\n",
        "    alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\r\n",
        "    diff = fake_images - real_images\r\n",
        "    interpolated = real_images + alpha * diff\r\n",
        "\r\n",
        "    with tf.GradientTape() as gp_tape:\r\n",
        "      gp_tape.watch(interpolated)\r\n",
        "      pred = self.discriminator(interpolated, training=True)\r\n",
        "      \r\n",
        "    grads = gp_tape.gradient(pred, [interpolated])[0]\r\n",
        "\r\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\r\n",
        "    gp = tf.reduce_mean((norm - 1.0) ** 2)\r\n",
        "    return gp\r\n",
        "\r\n",
        "  def train_step(self, real_images):\r\n",
        "    if isinstance(real_images, tuple):\r\n",
        "      real_images = real_images[0]\r\n",
        "    batch_size = tf.shape(real_images)[0]\r\n",
        "\r\n",
        "    for i in range(self.d_steps):\r\n",
        "      random_latent_vectors = tf.random.normal(\r\n",
        "          shape=(batch_size, self.latent_dim)\r\n",
        "      )\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "        fake_images = self.generator(random_latent_vectors, training=True)\r\n",
        "\r\n",
        "        fake_logits = self.discriminator(fake_images, training=True)\r\n",
        "        real_logits = self.discriminator(real_images, training=True)\r\n",
        "\r\n",
        "        d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\r\n",
        "\r\n",
        "        gp = self.gradient_penalty(batch_size, real_images, fake_images)\r\n",
        "\r\n",
        "        d_loss = d_cost + gp * self.gp_weight\r\n",
        "\r\n",
        "      d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\r\n",
        "      self.d_optimizer.apply_gradients(\r\n",
        "          zip(d_gradient, self.discriminator.trainable_variables)\r\n",
        "      )\r\n",
        "\r\n",
        "      random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "        generated_images = self.generator(random_latent_vectors, training=True)\r\n",
        "        gen_img_logits = self.discriminator(generated_images, training=True)\r\n",
        "        g_loss = self.g_loss_fn(gen_img_logits)\r\n",
        "\r\n",
        "      gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\r\n",
        "      self.g_optimizer.apply_gradients(\r\n",
        "          zip(gen_gradient, self.generator.trainable_variables)\r\n",
        "      )\r\n",
        "\r\n",
        "      return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfKNvPeTkjIN"
      },
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\r\n",
        "  def __init__(self, num_img=6, latent_dim=128):\r\n",
        "    self.num_img = num_img\r\n",
        "    self.latent_dim = latent_dim\r\n",
        "\r\n",
        "  def on_epoch_end(self, epoch, logs=None):\r\n",
        "    random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\r\n",
        "    generated_images = self.model.generator(random_latent_vectors)\r\n",
        "    generated_images = (generated_images * 127.5) + 127.5\r\n",
        "\r\n",
        "    for i in range(self.num_img):\r\n",
        "      img = generated_images[i].numpy()\r\n",
        "      img = keras.preprocessing.image.array_to_img(img)\r\n",
        "      img.save(\"generated_img_{i}_{epoch}.png\". format(i=i, epoch=epoch))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-2cxsCynPnZ",
        "outputId": "82b85942-2ecd-461e-a259-edf796d726e5"
      },
      "source": [
        "generator_optimizer = keras.optimizers.Adam(\r\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\r\n",
        ")\r\n",
        "\r\n",
        "discriminator_optimizer = keras.optimizers.Adam(\r\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\r\n",
        ")\r\n",
        "\r\n",
        "def discriminator_loss(real_img, fake_img):\r\n",
        "  real_loss = tf.reduce_mean(real_img)\r\n",
        "  fake_loss = tf.reduce_mean(fake_img)\r\n",
        "  return fake_loss - real_loss\r\n",
        "\r\n",
        "def generator_loss(fake_img):\r\n",
        "  return -tf.reduce_mean(fake_img)\r\n",
        "\r\n",
        "epochs = 20\r\n",
        "\r\n",
        "cbk = GANMonitor(num_img=3, latent_dim=noise_dim)\r\n",
        "\r\n",
        "wgan = WGAN(\r\n",
        "    discriminator= d_model,\r\n",
        "    generator = g_model,\r\n",
        "    latent_dim = noise_dim,\r\n",
        "    discriminator_extra_steps=3,\r\n",
        ")\r\n",
        "\r\n",
        "wgan.compile(\r\n",
        "    d_optimizer = discriminator_optimizer,\r\n",
        "    g_optimizer = generator_optimizer,\r\n",
        "    g_loss_fn = generator_loss,\r\n",
        "    d_loss_fn = discriminator_loss,\r\n",
        ")\r\n",
        "\r\n",
        "wgan.fit(train_images, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "118/118 [==============================] - 33s 229ms/step - d_loss: -5.3142 - g_loss: -16.4529\n",
            "Epoch 2/20\n",
            "118/118 [==============================] - 27s 228ms/step - d_loss: -5.6703 - g_loss: -16.1331\n",
            "Epoch 3/20\n",
            "118/118 [==============================] - 27s 229ms/step - d_loss: -5.0629 - g_loss: -14.1711\n",
            "Epoch 4/20\n",
            "118/118 [==============================] - 27s 230ms/step - d_loss: -4.5953 - g_loss: -10.0040\n",
            "Epoch 5/20\n",
            "118/118 [==============================] - 27s 231ms/step - d_loss: -4.3075 - g_loss: -7.5309\n",
            "Epoch 6/20\n",
            "118/118 [==============================] - 27s 232ms/step - d_loss: -3.8534 - g_loss: -6.8841\n",
            "Epoch 7/20\n",
            "118/118 [==============================] - 27s 233ms/step - d_loss: -3.5143 - g_loss: -6.2331\n",
            "Epoch 8/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -3.2486 - g_loss: -4.4125\n",
            "Epoch 9/20\n",
            "118/118 [==============================] - 27s 233ms/step - d_loss: -3.0467 - g_loss: -3.9618\n",
            "Epoch 10/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -2.8071 - g_loss: -4.7508\n",
            "Epoch 11/20\n",
            "118/118 [==============================] - 28s 234ms/step - d_loss: -2.6400 - g_loss: -3.8277\n",
            "Epoch 12/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -2.4604 - g_loss: -3.5085\n",
            "Epoch 13/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -2.2924 - g_loss: -3.0142\n",
            "Epoch 14/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -2.1855 - g_loss: -3.2829\n",
            "Epoch 15/20\n",
            "118/118 [==============================] - 28s 234ms/step - d_loss: -2.0506 - g_loss: -3.7681\n",
            "Epoch 16/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -1.9341 - g_loss: -2.3583\n",
            "Epoch 17/20\n",
            "118/118 [==============================] - 28s 234ms/step - d_loss: -1.8352 - g_loss: -2.5949\n",
            "Epoch 18/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -1.7194 - g_loss: -2.8446\n",
            "Epoch 19/20\n",
            "118/118 [==============================] - 28s 233ms/step - d_loss: -1.6509 - g_loss: -2.1867\n",
            "Epoch 20/20\n",
            "118/118 [==============================] - 28s 234ms/step - d_loss: -1.5493 - g_loss: -1.1463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f81600a72b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DrEKURco0NJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "294ac204-347f-4686-e9e1-f3c4694919ca"
      },
      "source": [
        "from IPython.display import Image, display\r\n",
        "\r\n",
        "display(Image(\"generated_img_0_19.png\"))\r\n",
        "display(Image(\"generated_img_1_19.png\"))\r\n",
        "display(Image(\"generated_img_2_19.png\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACo0lEQVR4nAXBzYtbZRQH4PM7531vbpJJJk1mJk7NRMG6aO1UrF1IF4qC+gfIgKBLBUEEXYnQlf+AuhKK6EZE0E2hVERQUBe1blSwmbbYFvsxbearMyaZ5N73nOPz4JAVKZiR8epljlWMEifLZnC482RSmqmq4vVeZJ8023kkCMjACOQOdzE+eaXdmL9qsX30nBrY4Qx3IsCNKjraXz7surVOwiAiY3eAnBi8Vxz0BuMKPfps3YlIGIGdiAgGkVhr3mr2rw3cEc2ZwUYgIiKp/pceNCudB/t+v0wGMXUO7iAyhyW2sXY3pqE0txLkGbOwAwLRHem9t7q2F76+8Er34c7zh1EyC8HdQdzK3n/qzyt5uzvXP15fzIemQdVJFKTpZGM63br4zJ318z/Feu+3mTOFPJcoIjGeunzmVYqPrbxb67716c2X66EWYMZgF8tfyvYukJfj8/W53viXzhLtg3Nym1G91jzxGf3+4bYP19b/6Wx0jqWNfwOosFCX/nV7XPHGbT5yaNbarYLD7f1J0AISO9kL4/uDFw92ae6j0a8ff7C5/N1O4hIyP1OWhSd+KPprfzTPhU8ufaVuQREohZBiuTTf2DPZuHQxV/rmZnMLrgYzoNZs7VStOJVosHztue+XVnZPf7u8xZPjOpihpWHh3mJ4u79++uc3u4+MsqOTv+a3M6xu3vUwsnhvOrTPJzeqi8WTt7y7faMcsabr4ylCKMpEqbxakN798m8nGhaoFCKiABeEIO4aKtZ454t2pKkQw7VwZyYmVSUqZ8X4x+HYfFqhwpKO2UoKMWQxckUisPIac8bVfC6rVB7KISwc8xCyahDBwtNMrejRyTMDOMASJXaDOW2eTYhSRiOZHjiESzO4QqUeeXqHsxNVacUGKSPY/y/iWLBiRmlGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAChElEQVR4nAXBTWucZRQG4Ps+53nnzTTtJGMThiRthtLW4hdaEITWgLgQF+7rL8jOjeg/cO3WLqwbuxNBiqvSFoWqEKGmFWKIWFL7kaRJxqTTGWfe9znn9Lp4FBXdZXJQlOPPbhfz14v+kGZQD7DMUJPQGq93rlTHY3Xj07EkzxFEqoM5IjzkwoezWux/9+b0Xm0SyQ3USLUEHHNfnvxv/+3JWxO+/L+CcKgQoICiS7h3t7uzMvnjw3caAZA0gTg9iOlL2/cmTrfLUae32IBEABANQETQPN+10W5th0/7ny8xoBRKeCDcudR+vP70iT3/4eetxffUIiJCXBWkkAd3z83c3pprn3r5t6uFhMNVBAHCfa9eOJP8Uevc+p39AyNBUhgGpkIerM2itIdPdmJju2UeHnQJFckWPlqdLtL6v1Ob7P++B4JwT06n0/jKLx6bazMnBoNYicYY4kIJU4Ima3di4WPtHcxf8EdEqZQQAUKFlMPBr7322XYqm1P5cDSGmbsEJYfqEavGM3/o/WOfnJn1GkkAqDSjVpg9G6blZn3W5Psrj2XBKw+VLIWoBWP+qPRXXyvy1W8qhTPMjSnZET7n1PCja1uHF7ut4o0vRhtft+Y2h8bopJETGIy+HbF388RL9k++MZx5/yeWQ3gvlVmzGTykfPWk2J+Xbm3vXw5hlnCpqlGopBKUjm9h+d2LHxxrKEXIOhlAd3/m2DmOndxb+aroE4iAR0qZMASA+63OWxOLVVkhAiTFJVONQsDW1YoJnJpPpGiiuyQ2UUdmMYYuonv+9GS32hUHk+dGSjUjQAfkQXPwVx6vUIWISuGpojRyiEvotenhwfW/d6cslXUWKl8AROdjCIOyzBUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACxklEQVR4nAXBS2hcZRQH8P8533fvnTu982pm0jRpzEhtRE0KVbswEh/opgiKSVF8VOymUkG34saNC10GUdwqdakoWlRciU9E7fSlQguCHZpm0kk6j2TuzJ3vO8ffj2IOBmBx1oGUyIp4Q9ZkAHlLOvAghSCE9+qr0foYHPkRS0ihHSlY2Y4YxgMUF3o7RimUzFAAVSMQAMYTCUzuvurPLY2cgtUSiIPpKsGrQsXn68dPAKJEbAIIJutzGQCoN0bDXu+tQxGxhGxDkB6t2xQBDEwuRD/p5J+NERZyrErWvPDgm4+GpfDeytHpxSNn1hZpeZ5pMbZ+ACfVO2s513/4TLP2yYU39v9UyvZuia0dtOxzuyU5axri/vmieGmtd2n7lScaGz1w/5rNxGO2vvpDfHu6+VrhsT3pf2mrfrXIY/nVsCGSa1eG+4O7bpWuv3xyhvc9/frJ83NF6GDMkQ14icvD5jP78l9+8GK73v/7owsLBwaiEM7gEfxCp+7uHJyeOvbQxna5uXX/5GgyAMOqA610b6Y7b7ftS2HY6R6oHDm0cz51CrAY0j3jxmpzlsu3dhf3Fjrtd3DjDyZisipQ6YXFeOrPTXS/cUDyYfzucDfIhKwRUGVWC4X5rxWUS4VObDYm/h2MFcaCo2C7Mh4+d3X21afeL3xeef7Ub1+t3mz9+LtPOMonjxw+t/Zp81zy2apPFpZw+b3ZojVZghk7kQ2zi7UHBuXtx914ZfRx49jF8ulWc2l9vXvDtobx4TuWO6VetfBXMys92VlZiJOd+aiWoxFZx8un27cVvvsWLg51Y0Mnknvc9Znv04zIiM4dPzu1dcURABWCiePhsNx1nimCLyZtk3oYFpiA2ae2lCabqmwN+8xpnG9bDkjUuzGLZ+2TcWThDWIgDOAEsCQUcJLfHTMTU+QMiCnIHBAoOSUrzE5Ugf8BvudMei72X8UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}