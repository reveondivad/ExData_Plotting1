{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distilGPT2-finetuned-MA-Meditations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reveondivad/ExData_Plotting1/blob/master/distilGPT2_finetuned_MA_Meditations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niZE8AHRdiEx"
      },
      "source": [
        "# Fine tune distilGPT-2 on Marco Aurelio Medidations for text generation\n",
        "\n",
        "> Author: [Manuel Romero / mrm8488](https://twitter.com/mrm8488)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-YqwhZzVZaU"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOss2aihVa_3",
        "outputId": "9b4cb6ce-a364-45ad-d858-bd58e3531ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/GITenberg/Meditations_2680/master/2680.txt -O text.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-03 21:32:51--  https://raw.githubusercontent.com/GITenberg/Meditations_2680/master/2680.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 425173 (415K) [text/plain]\n",
            "Saving to: ‘text.txt’\n",
            "\n",
            "text.txt            100%[===================>] 415.21K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-11-03 21:32:51 (8.65 MB/s) - ‘text.txt’ saved [425173/425173]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZndJ6XHhqRw"
      },
      "source": [
        "### Remove book index, introduction an so on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vFqJ4sUV7kG",
        "outputId": "6f2e9198-694d-442b-f95a-932e81d2ee68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wc -l text.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7212 text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptp9JF77XL72",
        "outputId": "fa632a64-7a2f-4508-b19f-506f1e08b0e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -88 text.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Project Gutenberg EBook of Meditations, by Marcus Aurelius\r\n",
            "\r\n",
            "This eBook is for the use of anyone anywhere at no cost and with\r\n",
            "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
            "re-use it under the terms of the Project Gutenberg License included\r\n",
            "with this eBook or online at www.gutenberg.org\r\n",
            "\r\n",
            "\r\n",
            "Title: Meditations\r\n",
            "\r\n",
            "Author: Marcus Aurelius\r\n",
            "\r\n",
            "Posting Date: December 25, 2008 [EBook #2680]\r\n",
            "Release Date: June, 2001\r\n",
            "\r\n",
            "Language: English\r\n",
            "\r\n",
            "Character set encoding: ASCII\r\n",
            "\r\n",
            "*** START OF THIS PROJECT GUTENBERG EBOOK MEDITATIONS ***\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Produced by J. Boulton\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "MEDITATIONS\r\n",
            "\r\n",
            "By Marcus Aurelius\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "CONTENTS\r\n",
            "\r\n",
            "\r\n",
            "     NOTES\r\n",
            "\r\n",
            "     INTRODUCTION\r\n",
            "\r\n",
            "     FIRST BOOK\r\n",
            "\r\n",
            "     SECOND BOOK\r\n",
            "\r\n",
            "     THIRD BOOK\r\n",
            "\r\n",
            "     FOURTH BOOK\r\n",
            "\r\n",
            "     FIFTH BOOK\r\n",
            "\r\n",
            "     SIXTH BOOK\r\n",
            "\r\n",
            "     SEVENTH BOOK\r\n",
            "\r\n",
            "     EIGHTH BOOK\r\n",
            "\r\n",
            "     NINTH BOOK\r\n",
            "\r\n",
            "     TENTH BOOK\r\n",
            "\r\n",
            "     ELEVENTH BOOK\r\n",
            "\r\n",
            "     TWELFTH BOOK\r\n",
            "\r\n",
            "     APPENDIX\r\n",
            "\r\n",
            "     GLOSSARY\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Original Transcriber's Notes:\r\n",
            "\r\n",
            "This text was scanned by J. Boulton using Textbridge OCR. The Greek\r\n",
            "portions of the text have been added by hand and they will require the\r\n",
            "standard \"Symbol\" font \"symbol.ttf\" to be installed in the system fonts\r\n",
            "folder. This is a standard Windows font, so should be present on most\r\n",
            "systems. To contact the scanner e-mail: magicjon@ic24.net INTRODUCTION\r\n",
            "This is the Plain Text version, see medma10h.txt or .zip for the HTML\r\n",
            "version with the various symbols mentioned above.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlgvv5boXpNZ"
      },
      "source": [
        "!cat text.txt | tail -7124 >> train.txt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEWjk9gqXQ31",
        "outputId": "eafc6eba-92af-4d2c-f530-83e7906c204a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -20 train.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INTRODUCTION\r\n",
            "\r\n",
            "\r\n",
            "MARCUS AURELIUS ANTONINUS was born on April 26, A.D. 121. His real name\r\n",
            "was M. Annius Verus, and he was sprung of a noble family which claimed\r\n",
            "descent from Numa, second King of Rome. Thus the most religious of\r\n",
            "emperors came of the blood of the most pious of early kings. His father,\r\n",
            "Annius Verus, had held high office in Rome, and his grandfather, of\r\n",
            "the same name, had been thrice Consul. Both his parents died young, but\r\n",
            "Marcus held them in loving remembrance. On his father's death Marcus\r\n",
            "was adopted by his grandfather, the consular Annius Verus, and there was\r\n",
            "deep love between these two. On the very first page of his book Marcus\r\n",
            "gratefully declares how of his grandfather he had learned to be gentle\r\n",
            "and meek, and to refrain from all anger and passion. The Emperor Hadrian\r\n",
            "divined the fine character of the lad, whom he used to call not Verus\r\n",
            "but Verissimus, more Truthful than his own name. He advanced Marcus to\r\n",
            "equestrian rank when six years of age, and at the age of eight made him\r\n",
            "a member of the ancient Salian priesthood. The boy's aunt, Annia Galeria\r\n",
            "Faustina, was married to Antoninus Pius, afterwards emperor. Hence it\r\n",
            "came about that Antoninus, having no son, adopted Marcus, changing his\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIIMcSigX3kC"
      },
      "source": [
        "!rm -rf text.txt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTifIFDQX-fH"
      },
      "source": [
        "## Install HF Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95hoiPoX79s",
        "outputId": "68b045a2-e2af-4176-cd28-a5181f50e87e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 49361 (delta 15), reused 30 (delta 4), pack-reused 49311\u001b[K\n",
            "Receiving objects: 100% (49361/49361), 36.51 MiB | 18.12 MiB/s, done.\n",
            "Resolving deltas: 100% (34423/34423), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHxOa9DLYLeU",
        "outputId": "de3e8512-8480-4d5f-d338-776049020a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q ./transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 890kB 3.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 17.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 27.3MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zpu389Ih0Kb"
      },
      "source": [
        "## Fine tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luYB1jc-8e_R",
        "outputId": "8e388d32-9b5a-4e30-bc4f-6b3111d1e331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls transformers/examples/language-modeling/\n",
        "!pwd\n",
        "!pip install datasets"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "README.md  run_clm.py  run_mlm.py  run_mlm_wwm.py  run_plm.py\n",
            "/content\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/f4/2a3d6aee93ae7fce6c936dda2d7f534ad5f044a21238f85e28f0b205adf0/datasets-1.1.2-py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from datasets) (3.0.12)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.10)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Collecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: pyarrow, xxhash, datasets\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.1.2 pyarrow-2.0.0 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWc0gU2kYb5i",
        "outputId": "565c4ed8-04ad-4d52-c9eb-5ed21009ec2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##!python /content/transformers/examples/language-modeling/run_clm.py \\\n",
        "#--model_type=gpt2 \\\n",
        "#--model_name_or_path=distilgpt2 \\\n",
        "#--do_train \\\n",
        "#--train_data_file=/content/train.txt \\\n",
        "#--num_train_epochs 100 \\\n",
        "#--output_dir model_output \\\n",
        "#--overwrite_output_dir \\\n",
        "#--save_steps 20000 \\\n",
        "#--per_gpu_train_batch_size 4\n",
        "!mkdir /content/tmp\n",
        "!python /content/transformers/examples/language-modeling/run_clm.py \\\n",
        "    --model_name_or_path=distilgpt2 \\\n",
        "    --train_file=/content/train.txt \\\n",
        "    --do_train \\\n",
        "    --output_dir=/content/tmp\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-03 21:33:24.853111: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/03/2020 21:33:26 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
            "11/03/2020 21:33:26 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/tmp', overwrite_output_dir=False, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov03_21-33-26_c769d5f80795', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/content/tmp', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139909587075256 acquired on /root/.cache/huggingface/datasets/d3dda449ff58b36f7d66762e475d20eb7a28790ac6059bd80bdbddec36610dcc.19b336b2eed2886a3b87b3a9ecf243731639cf554872c9aeb69992c476fd0e4c.py.lock\n",
            "Downloading: 2.71kB [00:00, 1.96MB/s]       \n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139909587075256 released on /root/.cache/huggingface/datasets/d3dda449ff58b36f7d66762e475d20eb7a28790ac6059bd80bdbddec36610dcc.19b336b2eed2886a3b87b3a9ecf243731639cf554872c9aeb69992c476fd0e4c.py.lock\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139909587075256 acquired on /root/.cache/huggingface/datasets/d3dda449ff58b36f7d66762e475d20eb7a28790ac6059bd80bdbddec36610dcc.19b336b2eed2886a3b87b3a9ecf243731639cf554872c9aeb69992c476fd0e4c.py.lock\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139909587075256 released on /root/.cache/huggingface/datasets/d3dda449ff58b36f7d66762e475d20eb7a28790ac6059bd80bdbddec36610dcc.19b336b2eed2886a3b87b3a9ecf243731639cf554872c9aeb69992c476fd0e4c.py.lock\n",
            "Using custom data configuration default\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139910536331616 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_text_default-3ef7b9a624ed5879_0.0.0_52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155.lock\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139910536331616 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_text_default-3ef7b9a624ed5879_0.0.0_52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155.lock\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139910536332120 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_text_default-3ef7b9a624ed5879_0.0.0_52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155.lock\n",
            "Downloading and preparing dataset text/default-3ef7b9a624ed5879 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-3ef7b9a624ed5879/0.0.0/52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155...\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139910536331672 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_text_default-3ef7b9a624ed5879_0.0.0_52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155.incomplete.lock\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139910536331672 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_text_default-3ef7b9a624ed5879_0.0.0_52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155.incomplete.lock\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-3ef7b9a624ed5879/0.0.0/52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155. Subsequent calls will reuse this data.\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139910536332120 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_text_default-3ef7b9a624ed5879_0.0.0_52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155.lock\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139906592451160 acquired on /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7.lock\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpk__e92eh\n",
            "Downloading: 100% 762/762 [00:00<00:00, 529kB/s]\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json in cache at /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7\n",
            "creating metadata file for /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7\n",
            "11/03/2020 21:33:27 - INFO - filelock -   Lock 139906592451160 released on /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7.lock\n",
            "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json from cache at /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7\n",
            "Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json from cache at /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7\n",
            "Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "11/03/2020 21:33:28 - INFO - filelock -   Lock 139906584559288 acquired on /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpsbeudad0\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 5.79MB/s]\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-vocab.json in cache at /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "creating metadata file for /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "11/03/2020 21:33:28 - INFO - filelock -   Lock 139906584559288 released on /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "11/03/2020 21:33:28 - INFO - filelock -   Lock 139906584559288 acquired on /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpurmxx2x0\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 3.61MB/s]\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-merges.txt in cache at /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "creating metadata file for /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "11/03/2020 21:33:29 - INFO - filelock -   Lock 139906584559288 released on /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "11/03/2020 21:33:29 - INFO - filelock -   Lock 139906585096320 acquired on /root/.cache/torch/transformers/b82347d34f9f4792fab81c324431b7f36f227da814ab0aca1d2e0d733c16709d.bcc7d9c641fe071e295c0b237661d39b7c69a1824aee7ad8199d87880f36474e.lock\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpg3tjakp4\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 7.54MB/s]\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-tokenizer.json in cache at /root/.cache/torch/transformers/b82347d34f9f4792fab81c324431b7f36f227da814ab0aca1d2e0d733c16709d.bcc7d9c641fe071e295c0b237661d39b7c69a1824aee7ad8199d87880f36474e\n",
            "creating metadata file for /root/.cache/torch/transformers/b82347d34f9f4792fab81c324431b7f36f227da814ab0aca1d2e0d733c16709d.bcc7d9c641fe071e295c0b237661d39b7c69a1824aee7ad8199d87880f36474e\n",
            "11/03/2020 21:33:29 - INFO - filelock -   Lock 139906585096320 released on /root/.cache/torch/transformers/b82347d34f9f4792fab81c324431b7f36f227da814ab0aca1d2e0d733c16709d.bcc7d9c641fe071e295c0b237661d39b7c69a1824aee7ad8199d87880f36474e.lock\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-vocab.json from cache at /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-merges.txt from cache at /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-tokenizer.json from cache at /root/.cache/torch/transformers/b82347d34f9f4792fab81c324431b7f36f227da814ab0aca1d2e0d733c16709d.bcc7d9c641fe071e295c0b237661d39b7c69a1824aee7ad8199d87880f36474e\n",
            "11/03/2020 21:33:29 - INFO - filelock -   Lock 139906592451160 acquired on /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c.lock\n",
            "https://cdn.huggingface.co/distilgpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpccnl936s\n",
            "Downloading: 100% 353M/353M [00:05<00:00, 65.9MB/s]\n",
            "storing https://cdn.huggingface.co/distilgpt2-pytorch_model.bin in cache at /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c\n",
            "creating metadata file for /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c\n",
            "11/03/2020 21:33:35 - INFO - filelock -   Lock 139906592451160 released on /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c.lock\n",
            "loading weights file https://cdn.huggingface.co/distilgpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "100% 8/8 [00:00<00:00, 36.83ba/s]\n",
            "100% 8/8 [00:00<00:00, 17.65ba/s]\n",
            "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
            "***** Running training *****\n",
            "  Num examples = 91\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 36\n",
            "  0% 0/36 [00:00<?, ?it/s]tcmalloc: large alloc 1646821376 bytes == 0x3a75ba000 @  0x7f3f77b81b6b 0x7f3f77ba1379 0x7f3f3a23392e 0x7f3f3a235946 0x7f3efb3fcbb3 0x7f3efaeb117a 0x7f3efaeb2293 0x7f3efb3b2edf 0x7f3efad71280 0x7f3efad718e0 0x7f3efb196f59 0x7f3efaaf4530 0x7f3efb2dc81c 0x7f3efb22d6ab 0x7f3efcf6ea2f 0x7f3efaaf4530 0x7f3efb2dc81c 0x7f3efb3c2cab 0x7f3efad77b39 0x7f3efad787ba 0x7f3efb333d60 0x7f3efcecb279 0x7f3efaaf4530 0x7f3efb2dc81c 0x7f3efb3c2beb 0x7f3f0a42fd27 0x50a4a5 0x50beb4 0x507be4 0x509900 0x50a2fd\n",
            "tcmalloc: large alloc 1645215744 bytes == 0x40c116000 @  0x7f3f77b81b6b 0x7f3f77ba1379 0x7f3f3a23392e 0x7f3f3a235946 0x7f3efaf119e5 0x7f3efb196af3 0x7f3efb187f97 0x7f3efb187c7d 0x7f3efb187f97 0x7f3efb292a1a 0x7f3efcf88a8d 0x7f3efb187f97 0x7f3efb292a1a 0x7f3efaf10c3e 0x7f3efb3260c1 0x7f3efce833e1 0x7f3efb361863 0x7f3efb275b31 0x7f3efaf2d469 0x7f3efb32e470 0x7f3efcf88089 0x7f3efb36151f 0x7f3efb3cc2e8 0x7f3f0a4bf163 0x50a4a5 0x50beb4 0x507be4 0x508ec2 0x594a01 0x59fd0e 0x50d256\n",
            "tcmalloc: large alloc 1645215744 bytes == 0x46e216000 @  0x7f3f77b81b6b 0x7f3f77ba1379 0x7f3f3a23392e 0x7f3f3a235946 0x7f3efaf119e5 0x7f3efb196af3 0x7f3efb187f97 0x7f3efb187c7d 0x7f3efb187f97 0x7f3efb292a1a 0x7f3efaf10c3e 0x7f3efaebc263 0x7f3efb196e4c 0x7f3efb1b21b4 0x7f3efb24a764 0x7f3efcf26d80 0x7f3efb1b21b4 0x7f3efb24a764 0x7f3efaebbd95 0x7f3efb33365b 0x7f3efcf124a1 0x7f3efab39473 0x7f3efb3e3361 0x7f3f0a43ce98 0x50a4a5 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4\n",
            "tcmalloc: large alloc 1645215744 bytes == 0x3a75ba000 @  0x7f3f77b81b6b 0x7f3f77ba1379 0x7f3f3a23392e 0x7f3f3a235946 0x7f3efaf119e5 0x7f3efb196af3 0x7f3efb187f97 0x7f3efb187c7d 0x7f3efb187f97 0x7f3efb292a1a 0x7f3efaf10c3e 0x7f3efb3260c1 0x7f3efb361863 0x7f3efb275b31 0x7f3efaf0a6f6 0x7f3efb329434 0x7f3efb361863 0x7f3efb275dd1 0x7f3efadb2591 0x7f3efb198441 0x7f3efb1b1463 0x7f3efb23c8f6 0x7f3efcef1b2d 0x7f3efb1b1463 0x7f3efb23c8f6 0x7f3efcddd970 0x7f3efd413bb7 0x7f3efd40f400 0x7f3efd40ffa1 0x7f3efd40d6bc 0x7f3f0a78c76c\n",
            "100% 36/36 [05:47<00:00,  8.21s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'epoch': 3.0}\n",
            "100% 36/36 [05:47<00:00,  9.64s/it]\n",
            "Saving model checkpoint to /content/tmp\n",
            "Configuration saved in /content/tmp/config.json\n",
            "Model weights saved in /content/tmp/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Ui_GI2h-yF"
      },
      "source": [
        "## Generate text with our fine tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv7UrthKjVUw",
        "outputId": "03fe7a21-a6f9-4164-c9da-2d2ff56f7e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/transformers/examples/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=/content/tmp \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 100 \\\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-03 21:40:38.539734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/03/2020 21:40:40 - WARNING - __main__ -   device: cpu, n_gpu: 0, 16-bits training: False\n",
            "11/03/2020 21:40:44 - INFO - __main__ -   Namespace(device=device(type='cpu'), fp16=False, k=0, length=100, model_name_or_path='/content/tmp', model_type='gpt2', n_gpu=0, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> \n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "<|endoftext|>\"…What are you, Mad Men?\"\n",
            "\n",
            "\n",
            "When Beni, 25, writes to him in his memoirs on Christmas Day, having died, and disinterred and attempted to suppress his thought, it was said that he had used a second of him as an antidote. (The line is that this is true, and, forgive us, it is true, to us, indeed, that it is true.)\n",
            "What he understood was that what was made of him was not\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "<|endoftext|>Favorite aspect of writing: *Philip says he‽( himself) is an introvert - so it sounds like a an off-chance father of a child. *Philip reminds me of someone who uses novels. The character is lazy, his natural drive is just like that of a person.... *Philip is not as skilled in poetry or comedy as the one that writes his novels. *Philip is a plain, confidentman who rarely gets to write anything that he does in\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "<|endoftext|>Δδοάύραέλευζίσις θέλεατηρ, Ωενέτικονωνς ήκότης.\n",
            "Δδεοάύραέλευζίσις θέλεατηρ, �\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "<|endoftext|>\n",
            "Selected 12-copy Catalog : 14-page Poster & Layout for all Penthouse Classics: From 1965-1966 10-page 18-page Poster & Layout for all Penthouse Classics : 14-page Personal Guide to Selected Booksellers: Some Introduction to Commercial Penthouse Classics: From 1965-1966 15-page 3-page Graphic Set for Penthouse Classics : 14-page Complete with commercial Penthouse Classics: From 1965-1966 18-page 5-page 3-page Two\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "<|endoftext|>A number of ethics concerns at French women's organisations including the SEAP and the Auxerre-Notre Dame University. Partly because the incidents of prostitution took place at 14, while other victims were targeted or also tortured.In April 2015 it was revealed that three men who were banned from using the bathroom of their own children were assaulted and hanged for their crimes.Experts warn of increased suicide and drug abuse in France.PARIS (AFP) - A number of countries including the United Kingdom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JspKNYq4pn4x"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}