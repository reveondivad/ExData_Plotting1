{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of GPT2_with_Javascript_interface_POC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reveondivad/ExData_Plotting1/blob/master/Copy_of_GPT2_with_Javascript_interface_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMMtepKIwxR8"
      },
      "source": [
        "#This is proof of concept that GPT-2 can be run from colab with Javascript interface\n",
        "**Q: How to do?**\n",
        "\n",
        "A: \n",
        "1. Runtime -> Change runtime type -> Hardware accelerator -> GPU\n",
        "2. Runtime -> Reset all runtimes\n",
        "3. Runtime -> Run all\n",
        "4. Scroll down and wait until you see the little window\n",
        "5. Type text\n",
        "6. The button \"Continue with GPT-2\" will invoke GPT-2 and it will continue your text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGUX9yKxnaRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8883f3c-eadb-4a5d-b9da-100862701c70"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/gpt2ent/gpt-2-simple.git\n",
        "%cd gpt-2-simple\n",
        "!git checkout context-trim\n",
        "!pip install .\n",
        "%cd ..\n",
        "!git clone https://github.com/gpt2ent/gpt2colab-js.git\n",
        "%cd gpt2colab-js\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "\n",
        "import re\n",
        "\n",
        "#Determining the graphics card used by colab: full model can run only on P100\n",
        "\n",
        "try:\n",
        "    !cat /proc/driver/nvidia/gpus/0000:00:04.0/information >> /content/card_info.txt\n",
        "    with open('/content/card_info.txt','r') as f:\n",
        "        graphics_card = re.split('\\n|\\t\\t ',f.read())[1]\n",
        "\n",
        "    if not graphics_card.startswith(\"Tesla P100\"):\n",
        "        print(\"=\"*90+'\\n'+\"=\"*90+'\\n\\n')\n",
        "        print('\\n\\tYour current GPU - %s - cannot fit the full GPT-2 model!' % graphics_card)\n",
        "        print('\\n\\tFalling back on 774M model.')\n",
        "        print('\\n\\tNothing I can do. just pray to Google to give you a P100')\n",
        "        print('\\t\\tnext time. ¯\\_(ツ)_/¯')\n",
        "        print('\\n\\tAlso you might try TPU runtime.')\n",
        "        print('\\n\\n'+\"=\"*90+'\\n'+\"=\"*90+'\\n\\n')\n",
        "        model_name = \"774M\"\n",
        "        spinner_speed = \"300ms\"\n",
        "    else:\n",
        "        print('GPU: %s' % graphics_card)\n",
        "        model_name = \"1558M\"\n",
        "        spinner_speed = '400ms'\n",
        "except IndexError:\n",
        "    print(\"=\"*90+'\\n'+\"=\"*90+'\\n\\n')\n",
        "    print('\\n\\tYou\\'re not in a GPU runtime.\\n')\n",
        "    print('\\n\\tTrying 1558M model anyways - assuming you\\'re on a good TPU.')\n",
        "    print('\\n\\tIf it fails, you have to go to Runtime -> Change runtime type')\n",
        "    print('\\n\\tand choose GPU.')\n",
        "    print('\\n\\n'+\"=\"*90+'\\n'+\"=\"*90+'\\n\\n')\n",
        "    model_name = \"1558M\"\n",
        "    spinner_speed = \"1200ms\"\n",
        "\n",
        "\n",
        "#Overwrite default model choice\n",
        "#model_name = \"1558M\"\n",
        "#model_name = \"774M\"\n",
        "#model_name = \"124M\"\n",
        "#model_name = \"355M\"\n",
        "\n",
        "\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "    print(f\"Downloading {model_name} model...\")\n",
        "    gpt2.download_gpt2(model_name=model_name)\n",
        "  \n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "\n",
        "generate_count = 0\n",
        "\n",
        "import google.colab.output\n",
        "\n",
        "def overlap(a, b):\n",
        "    return max(i for i in range(len(b)+1) if a.endswith(b[:i]))\n",
        "\n",
        "\n",
        "def ai_generate(prefix, temp, top_k, length):\n",
        "    global sess\n",
        "    global generate_count\n",
        "\n",
        "    temp = float(temp)\n",
        "    top_k = int(top_k)\n",
        "    length = int(length)\n",
        "    result = gpt2.generate(sess, model_name=model_name, prefix=prefix, temperature=temp,\n",
        "                        top_k=top_k, length=length, include_prefix=False, return_as_list=True)[0]\n",
        "    \n",
        "    j = overlap(prefix, result)\n",
        "    result = result[j:]\n",
        "    \n",
        "    generate_count += 1\n",
        "    if generate_count == 6:\n",
        "          #prevent memory leak as in https://github.com/minimaxir/gpt-2-simple/issues/71\n",
        "          tf.reset_default_graph()\n",
        "          sess.close()\n",
        "          sess = gpt2.start_tf_sess()\n",
        "          gpt2.load_gpt2(sess, model_name=model_name)\n",
        "          generate_count = 0\n",
        "    return result\n",
        "\n",
        "#register callback for Javascript\n",
        "google.colab.output.register_callback('ai_generate', ai_generate)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'gpt-2-simple'...\n",
            "remote: Enumerating objects: 526, done.\u001b[K\n",
            "remote: Total 526 (delta 0), reused 0 (delta 0), pack-reused 526\u001b[K\n",
            "Receiving objects: 100% (526/526), 208.58 KiB | 868.00 KiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n",
            "/content/gpt-2-simple\n",
            "Branch 'context-trim' set up to track remote branch 'context-trim' from 'origin'.\n",
            "Switched to a new branch 'context-trim'\n",
            "Processing /content/gpt-2-simple\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple==0.7.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple==0.7.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple==0.7.1) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple==0.7.1) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple==0.7.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple==0.7.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple==0.7.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple==0.7.1) (3.0.4)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=24428 sha256=060001c47a19f33ad2f7c08ff11c3bc6f477a587fd96d9567480318babf0d5a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/70/96/853c071e7f781ca80870f43d53102ac385a0fe2255d504475f\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n",
            "/content\n",
            "Cloning into 'gpt2colab-js'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 27 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n",
            "/content/gpt2colab-js\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "==========================================================================================\n",
            "==========================================================================================\n",
            "\n",
            "\n",
            "\n",
            "\tYour current GPU - Tesla V100-SXM2-16GB - cannot fit the full GPT-2 model!\n",
            "\n",
            "\tFalling back on 774M model.\n",
            "\n",
            "\tNothing I can do. just pray to Google to give you a P100\n",
            "\t\tnext time. ¯\\_(ツ)_/¯\n",
            "\n",
            "\tAlso you might try TPU runtime.\n",
            "\n",
            "\n",
            "==========================================================================================\n",
            "==========================================================================================\n",
            "\n",
            "\n",
            "Downloading 774M model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 233Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 85.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 357Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:37, 82.5Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 155Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 135Mit/s]                                                       \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/774M/model.ckpt\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdyRipC0o8vR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "557e5f9a-a3cf-4ef1-905e-9541d8a93d47"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "#spinner from https://codepen.io/vovchisko/pen/vROoYQ\n",
        "spinner_css = \"\"\"\n",
        "<style>\n",
        "@keyframes c-inline-spinner-kf {\n",
        "  0% {\n",
        "    transform: rotate(0deg);\n",
        "  }\n",
        "  100% {\n",
        "    transform: rotate(360deg);\n",
        "  }\n",
        "}\n",
        "\n",
        ".c-inline-spinner,\n",
        ".c-inline-spinner:before {\n",
        "  display: inline-block;\n",
        "  width: 11px;\n",
        "  height: 11px;\n",
        "  transform-origin: 50%;\n",
        "  border: 2px solid transparent;\n",
        "  border-color: #74a8d0 #74a8d0 transparent transparent;\n",
        "  border-radius: 50%;\n",
        "  content: \"\";\n",
        "  animation: linear c-inline-spinner-kf \"\"\"+spinner_speed+\"\"\" infinite;\n",
        "  position: relative;\n",
        "  vertical-align: inherit;\n",
        "  line-height: inherit;\n",
        "}\n",
        ".c-inline-spinner {\n",
        "  top: 3px;\n",
        "  margin: 0 3px;\n",
        "}\n",
        ".c-inline-spinner:before {\n",
        "  border-color: #74a8d0 #74a8d0 transparent transparent;\n",
        "  position: absolute;\n",
        "  left: -2px;\n",
        "  top: -2px;\n",
        "  border-style: solid;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "input_form = \"\"\"\n",
        "<link rel=\"stylesheet\" href=\"https://unpkg.com/purecss@1.0.1/build/pure-min.css\" integrity=\"sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47\" crossorigin=\"anonymous\">\n",
        "\n",
        "<div style=\"background-color:white; border:solid #ccc; width:800px; padding:20px; color: black;\">\n",
        "<p>You have currently loaded %s model</p>\n",
        "<textarea id=\"main_textarea\" cols=\"75\" rows=\"20\" style=\"font-family: 'Liberation Serif', 'DejaVu Serif', Georgia, 'Times New Roman', Times, serif; font-size: 13pt; padding:10px;\"></textarea><br>\n",
        "<div class=\"pure-form pure-form-aligned\">\n",
        "    <div class=\"pure-control-group\">\n",
        "      <label for=\"temp\">Temperature:</label>\n",
        "      <input type=\"number\" min=\"0.00\" max=\"999.99\" step=\"0.01\" id=\"temp\" value=\"0.70\" style=\"background-color: white;\">\n",
        "    </div>\n",
        "    <div class=\"pure-control-group\">\n",
        "        <label for=\"top_k\">top_k:</label>\n",
        "        <input type=\"number\" min=\"0\" max=\"9999\" id=\"top_k\" value=\"40\" style=\"background-color: white;\">\n",
        "    </div>\n",
        "    <div class=\"pure-control-group\">\n",
        "        <label for=\"length\">Generate how much:</label>\n",
        "        <input type=\"number\" id=\"length\" min=\"1\" max=\"1023\" value=\"10\" style=\"background-color: white;\">\n",
        "    </div>\n",
        "    <div style=\"width: 300px; display: block; margin-left: auto !important; margin-right: auto !important;\">\n",
        "        <p><button class=\"pure-button pure-button-primary\" style=\"font-size: 125%%;\" onclick=\"generate()\">Continue with GPT-2</button>\n",
        "        <span class=\"c-inline-spinner\" style=\"visibility: hidden;\" id=\"spinner\"></span></p>\n",
        "    </div>\n",
        "</div>\n",
        "</div>\n",
        "\"\"\" % model_name\n",
        "\n",
        "javascript = \"\"\"\n",
        "<script type=\"text/Javascript\">\n",
        "    function desanitize(text) {\n",
        "        return text.slice(1,-1).replace(/\\\\\\\\n/g, \"\\\\n\").replace(/\\\\\\\\'/g, \"'\");\n",
        "    };\n",
        "\n",
        "    function add_text(text) {\n",
        "        var deftext = document.getElementById('main_textarea').value;\n",
        "        document.getElementById('main_textarea').value = deftext + text;\n",
        "    };\n",
        "\n",
        "    function generate(){\n",
        "        var prefix = document.getElementById('main_textarea').value;\n",
        "        var temp = document.getElementById('temp').value;\n",
        "        var top_k = document.getElementById('top_k').value;\n",
        "        var length = document.getElementById('length').value;\n",
        "        \n",
        "        var kernel = google.colab.kernel;\n",
        "        var resultPromise = kernel.invokeFunction(\"ai_generate\", [prefix,temp,top_k,length]); // developer, look here\n",
        "        resultPromise.then(\n",
        "            function(value) {\n",
        "              add_text(desanitize(value.data[\"text/plain\"]));\n",
        "              document.getElementById('spinner').style = \"visibility: hidden;\";\n",
        "        });\n",
        "        document.getElementById('spinner').style = \"visibility: visible;\";\n",
        "    };\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "HTML(spinner_css + input_form + javascript)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "@keyframes c-inline-spinner-kf {\n",
              "  0% {\n",
              "    transform: rotate(0deg);\n",
              "  }\n",
              "  100% {\n",
              "    transform: rotate(360deg);\n",
              "  }\n",
              "}\n",
              "\n",
              ".c-inline-spinner,\n",
              ".c-inline-spinner:before {\n",
              "  display: inline-block;\n",
              "  width: 11px;\n",
              "  height: 11px;\n",
              "  transform-origin: 50%;\n",
              "  border: 2px solid transparent;\n",
              "  border-color: #74a8d0 #74a8d0 transparent transparent;\n",
              "  border-radius: 50%;\n",
              "  content: \"\";\n",
              "  animation: linear c-inline-spinner-kf 300ms infinite;\n",
              "  position: relative;\n",
              "  vertical-align: inherit;\n",
              "  line-height: inherit;\n",
              "}\n",
              ".c-inline-spinner {\n",
              "  top: 3px;\n",
              "  margin: 0 3px;\n",
              "}\n",
              ".c-inline-spinner:before {\n",
              "  border-color: #74a8d0 #74a8d0 transparent transparent;\n",
              "  position: absolute;\n",
              "  left: -2px;\n",
              "  top: -2px;\n",
              "  border-style: solid;\n",
              "}\n",
              "</style>\n",
              "\n",
              "<link rel=\"stylesheet\" href=\"https://unpkg.com/purecss@1.0.1/build/pure-min.css\" integrity=\"sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47\" crossorigin=\"anonymous\">\n",
              "\n",
              "<div style=\"background-color:white; border:solid #ccc; width:800px; padding:20px; color: black;\">\n",
              "<p>You have currently loaded 774M model</p>\n",
              "<textarea id=\"main_textarea\" cols=\"75\" rows=\"20\" style=\"font-family: 'Liberation Serif', 'DejaVu Serif', Georgia, 'Times New Roman', Times, serif; font-size: 13pt; padding:10px;\"></textarea><br>\n",
              "<div class=\"pure-form pure-form-aligned\">\n",
              "    <div class=\"pure-control-group\">\n",
              "      <label for=\"temp\">Temperature:</label>\n",
              "      <input type=\"number\" min=\"0.00\" max=\"999.99\" step=\"0.01\" id=\"temp\" value=\"0.70\" style=\"background-color: white;\">\n",
              "    </div>\n",
              "    <div class=\"pure-control-group\">\n",
              "        <label for=\"top_k\">top_k:</label>\n",
              "        <input type=\"number\" min=\"0\" max=\"9999\" id=\"top_k\" value=\"40\" style=\"background-color: white;\">\n",
              "    </div>\n",
              "    <div class=\"pure-control-group\">\n",
              "        <label for=\"length\">Generate how much:</label>\n",
              "        <input type=\"number\" id=\"length\" min=\"1\" max=\"1023\" value=\"10\" style=\"background-color: white;\">\n",
              "    </div>\n",
              "    <div style=\"width: 300px; display: block; margin-left: auto !important; margin-right: auto !important;\">\n",
              "        <p><button class=\"pure-button pure-button-primary\" style=\"font-size: 125%;\" onclick=\"generate()\">Continue with GPT-2</button>\n",
              "        <span class=\"c-inline-spinner\" style=\"visibility: hidden;\" id=\"spinner\"></span></p>\n",
              "    </div>\n",
              "</div>\n",
              "</div>\n",
              "\n",
              "<script type=\"text/Javascript\">\n",
              "    function desanitize(text) {\n",
              "        return text.slice(1,-1).replace(/\\\\n/g, \"\\n\").replace(/\\\\'/g, \"'\");\n",
              "    };\n",
              "\n",
              "    function add_text(text) {\n",
              "        var deftext = document.getElementById('main_textarea').value;\n",
              "        document.getElementById('main_textarea').value = deftext + text;\n",
              "    };\n",
              "\n",
              "    function generate(){\n",
              "        var prefix = document.getElementById('main_textarea').value;\n",
              "        var temp = document.getElementById('temp').value;\n",
              "        var top_k = document.getElementById('top_k').value;\n",
              "        var length = document.getElementById('length').value;\n",
              "        \n",
              "        var kernel = google.colab.kernel;\n",
              "        var resultPromise = kernel.invokeFunction(\"ai_generate\", [prefix,temp,top_k,length]); // developer, look here\n",
              "        resultPromise.then(\n",
              "            function(value) {\n",
              "              add_text(desanitize(value.data[\"text/plain\"]));\n",
              "              document.getElementById('spinner').style = \"visibility: hidden;\";\n",
              "        });\n",
              "        document.getElementById('spinner').style = \"visibility: visible;\";\n",
              "    };\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}